{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1. Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2. Define the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that create the episode data - sample randomaly\n",
    "def get_data(episode_size,policy,mode):\n",
    "    global dataset\n",
    "    if mode=='train':\n",
    "        if policy==0:\n",
    "             dataset=data.sample(n=episode_size)\n",
    "        else:\n",
    "            dataset=data\n",
    "    else:\n",
    "        dataset = pd.read_csv(location + '/' + file +'_test_int.csv', index_col=0)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that separate the episode data into features and label\n",
    "def data_separate (dataset):\n",
    "    global X\n",
    "    global y    \n",
    "    X = dataset.iloc[:,0:dataset.shape[1]-1]  # all rows, all the features and no labels\n",
    "    y = dataset.iloc[:, -1]  # all rows, label only\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that split the episode data into train and test\n",
    "def data_split(X,y):\n",
    "    global X_train_main\n",
    "    global X_test_main   \n",
    "    global y_train\n",
    "    global y_test  \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_main, X_test_main, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "    return X_train_main, X_test_main, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that chooses exploration or explotation method\n",
    "def exploration_explotation(epsilon):\n",
    "    global exploration \n",
    "    if np.random.rand() < epsilon:  \n",
    "        exploration=1\n",
    "    else:\n",
    "        exploration=0    \n",
    "    return exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that returns all available actions in the state given as an argument: \n",
    "def available_actions(number_of_columns,columns,initial_state,current_state,trashold, exploration):\n",
    "    global exclude\n",
    "    global all_columns\n",
    "#    exclude=[]\n",
    "    all_columns=np.arange(number_of_columns+1)\n",
    "    # remove columns that have been already selected\n",
    "    exclude=columns.copy()\n",
    "    # remove the initial_state and the current_state\n",
    "    exclude.extend([initial_state, current_state])\n",
    "    available_act = list(set(all_columns)-set(exclude))\n",
    "    # remove actions that have negetiv Q value\n",
    "    if exploration==0:\n",
    "        index = np.where(Q[current_state,available_act] > trashold)[1]\n",
    "        available_act= [available_act[i] for i in index.tolist()]\n",
    "    return available_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that chooses which action to be performed according to exploration - explotation method\n",
    "def sample_next_action(current_state, Q, available_act, exploration):\n",
    "    global available_act_q_value\n",
    "    available_act_q_value=np.array(Q[current_state,available_act]).reshape(-1,).tolist()\n",
    "    if exploration==1: \n",
    "        #random selection\n",
    "        next_action = int(np.random.choice(available_act,1))\n",
    "    else: \n",
    "        #greedy selection according to max value \n",
    "        maxQ=max(available_act_q_value)\n",
    "        count = available_act_q_value.count(maxQ)\n",
    "        if count > 1:\n",
    "            max_columns =[i for i in range(len(available_act_q_value)) if available_act_q_value[i] == maxQ]\n",
    "            i = np.random.choice(max_columns)\n",
    "        else:\n",
    "            i = available_act_q_value.index(maxQ)\n",
    "        next_action=available_act[i]        \n",
    "    return next_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# function that update a list with all selected columns in the episode\n",
    "def update_columns(action, columns):\n",
    "    update_columns=columns\n",
    "    update_columns.append(action)\n",
    "    return update_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# function that update the X_train and X_test according to the current episode columns list \n",
    "def update_X_train_X_test(columns,X_train_main, X_test_main):\n",
    "    X_train=X_train_main.iloc[:,columns]\n",
    "    X_test=X_test_main.iloc[:,columns]\n",
    "    X_train=pd.DataFrame(X_train)\n",
    "    X_test=pd.DataFrame(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that run the learner and get the error to the current episode columns list\n",
    "def Learner(X_train, X_test,y_train, y_test):\n",
    "    global learner\n",
    "    global y_pred\n",
    "    if learner_model == 'DT':\n",
    "        learner = tree.DecisionTreeClassifier()\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        y_pred = learner.predict(X_test)\n",
    "    elif learner_model == 'KNN':\n",
    "        learner = KNeighborsClassifier(metric='hamming',n_neighbors=5)\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        y_pred = learner.predict(X_test)        \n",
    "    elif learner_model == 'SVM':\n",
    "        learner = SVC()\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        y_pred = learner.predict(X_test)        \n",
    "    elif learner_model == 'NB':\n",
    "        learner = MultinomialNB()\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        y_pred = learner.predict(X_test)\n",
    "    elif learner_model == 'AB':\n",
    "        learner = AdaBoostClassifier()\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        y_pred = learner.predict(X_test)  \n",
    "    elif learner_model == 'GB':\n",
    "        learner = GradientBoostingClassifier()\n",
    "        learner = learner.fit(X_train, y_train)\n",
    "        y_pred = learner.predict(X_test)  \n",
    "    accuracy=metrics.accuracy_score(y_test, y_pred)\n",
    "    error=1-accuracy\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Function that updates the Q matrix according to the path selected and the Q \n",
    "def q_update(current_state ,action,learning_rate, reward):\n",
    "    # next_state = current action\n",
    "    max_index = np.where(Q[action,] == np.max(Q[action,]))[1]    \n",
    "    if max_index.shape[0] > 1:\n",
    "        #np.random.seed(seed)\n",
    "        max_index = int(np.random.choice(max_index, size = 1))\n",
    "    else:\n",
    "        max_index = int(max_index)\n",
    "    max_value = Q[action, max_index]\n",
    "    #we start with 1 for all Q values and update with reward only at the 1st time\n",
    "    if Q[current_state, action]==1:\n",
    "        Q[current_state, action] = learning_rate*reward\n",
    "    else:\n",
    "         Q[current_state, action] = Q[current_state, action]+ learning_rate*(reward + (discount_factor * max_value)-Q[current_state, action])\n",
    "    #Q[current_state, action] = Q[current_state, action]+ learning_rate*(reward + (discount_factor * max_value)-Q[current_state, action])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiment mangment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3. Define the parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## for run time ##\n",
    "N_features=5\n",
    "N_data=1\n",
    "## for run time ##\n",
    "\n",
    "#Experiment: \n",
    "experiment='test'\n",
    "number_of_experiment=1\n",
    "\n",
    "# Dataset parameters #\n",
    "location = 'Datasets/adult'\n",
    "outputlocation='Datasets'\n",
    "file='adult' #adult #diabetic_data #no_show\n",
    "#np.random.seed(3)\n",
    "\n",
    "# Q learning parameter # \n",
    "learning_rate=0.005\n",
    "discount_factor=0\n",
    "epsilon = 0.1\n",
    "\n",
    "# Learner and episode parameters #\n",
    "learner_model = 'DT' #DT #KNN #SVM\n",
    "episode_size=100\n",
    "internal_trashold=0\n",
    "external_trashold=0\n",
    "filename= file +'_int.csv'\n",
    "\n",
    "#Experiments folder management: \n",
    "if not os.path.exists('/Experiments'):\n",
    "    os.makedirs('/Experiments') \n",
    "if not os.path.exists('Experiments/'+ str(experiment)):\n",
    "    os.makedirs('Experiments/'+ str(experiment))\n",
    "else:\n",
    "    shutil.rmtree('Experiments/'+ str(experiment))          #removes all the subdirectories!\n",
    "    os.makedirs('Experiments/'+ str(experiment))\n",
    "writer = pd.ExcelWriter('Experiments/'+ str(experiment) + '/df.xlsx') \n",
    "\n",
    "\n",
    "\n",
    "text_file = open('Experiments/'+ str(experiment) +'/parameters.txt', \"w\")\n",
    "text_file.write('experiment: ' + str(experiment)+ '\\n')\n",
    "text_file.write('number of experiments: ' + str(number_of_experiment)+ '\\n')\n",
    "text_file.write('file: ' + str(file)+ '\\n')\n",
    "text_file.write('learner model: ' + str(learner_model)+ '\\n')\n",
    "text_file.write('episode size: ' + str(episode_size)+ '\\n')\n",
    "#text_file.write('numbers of epocs: ' + str(epocs)+ '\\n')\n",
    "text_file.write('internal trashold: ' + str(internal_trashold)+ '\\n')\n",
    "text_file.write('external trashold: ' + str(external_trashold)+ '\\n')\n",
    " \n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4. Run all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments 0 start\n",
      "number of columns: 5 (exclude class column)\n",
      "Number of episodes: 2443.0\n",
      "initial state number: 5 (the last dummy column we have created)\n",
      "episode 1 start\n",
      "episode columns: [4, 3, 1, 2, 0] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[1, 4, 2, 3, 0] train accuracy: 0.817846909537454 test accuracy: 0.7900552486187845\n",
      "episode 1 end\n",
      "episode 2 start\n",
      "episode columns: [3, 4, 1, 2, 0] epsilon: 0.9 learning rate: 0.09 error: 0.25\n",
      "episode policy:[1, 0, 4, 2, 3] train accuracy: 0.817846909537454 test accuracy: 0.7845303867403315\n",
      "episode 2 end\n",
      "episode 3 start\n",
      "episode columns: [2, 1, 0, 3, 4] epsilon: 0.9 learning rate: 0.09 error: 0.09999999999999998\n",
      "episode policy:[0, 4, 2, 3] train accuracy: 0.764428980761359 test accuracy: 0.7845303867403315\n",
      "episode 3 end\n",
      "episode 4 start\n",
      "episode columns: [4, 3, 2, 1, 0] epsilon: 0.9 learning rate: 0.09 error: 0.4\n",
      "episode policy:[0, 1, 3, 2, 4] train accuracy: 0.817846909537454 test accuracy: 0.7863720073664825\n",
      "episode 4 end\n",
      "episode 5 start\n",
      "episode columns: [2, 3, 4, 1, 0] epsilon: 0.9 learning rate: 0.09 error: 0.15000000000000002\n",
      "episode policy:[0, 4, 2, 3] train accuracy: 0.764428980761359 test accuracy: 0.7918968692449355\n",
      "episode 5 end\n",
      "episode 6 start\n",
      "episode columns: [4, 3, 0, 2, 1] epsilon: 0.9 learning rate: 0.09 error: 0.050000000000000044\n",
      "episode policy:[0, 1, 4, 2, 3] train accuracy: 0.817846909537454 test accuracy: 0.7955801104972375\n",
      "episode 6 end\n",
      "episode 7 start\n",
      "episode columns: [0, 3, 2, 4, 1] epsilon: 0.9 learning rate: 0.09 error: 0.15000000000000002\n",
      "episode policy:[1, 4, 0] train accuracy: 0.7975849365534179 test accuracy: 0.7661141804788214\n",
      "episode 7 end\n",
      "episode 8 start\n",
      "episode columns: [4, 1, 3, 2, 0] epsilon: 0.9 learning rate: 0.09 error: 0.15000000000000002\n",
      "episode policy:[1, 4, 0] train accuracy: 0.7975849365534179 test accuracy: 0.7661141804788214\n",
      "episode 8 end\n",
      "episode 9 start\n",
      "episode columns: [0, 2, 3, 1, 4] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[1, 0, 4, 2] train accuracy: 0.8223495702005731 test accuracy: 0.7697974217311234\n",
      "episode 9 end\n",
      "episode 10 start\n",
      "episode columns: [1, 0, 3, 2, 4] epsilon: 0.9 learning rate: 0.09 error: 0.15000000000000002\n",
      "episode policy:[4, 2, 1, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7624309392265194\n",
      "episode 10 end\n",
      "episode 11 start\n",
      "episode columns: [0, 3, 1] epsilon: 0.9 learning rate: 0.09 error: 0.25\n",
      "episode policy:[4, 2, 1, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7697974217311234\n",
      "episode 11 end\n",
      "episode 12 start\n",
      "episode columns: [2, 1, 0, 3, 4] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[4, 2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7900552486187845\n",
      "episode 12 end\n",
      "episode 13 start\n",
      "episode columns: [3, 4, 1, 2, 0] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[4, 0, 1] train accuracy: 0.7975849365534179 test accuracy: 0.7661141804788214\n",
      "episode 13 end\n",
      "episode 14 start\n",
      "episode columns: [3, 2, 1, 0, 4] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[4, 0, 1] train accuracy: 0.7975849365534179 test accuracy: 0.7642725598526704\n",
      "episode 14 end\n",
      "episode 15 start\n",
      "episode columns: [4, 0, 2, 3, 1] epsilon: 0.9 learning rate: 0.09 error: 0.25\n",
      "episode policy:[4, 2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7900552486187845\n",
      "episode 15 end\n",
      "episode 16 start\n",
      "episode columns: [2, 4, 3, 1, 0] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[4, 2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7882136279926335\n",
      "episode 16 end\n",
      "episode 17 start\n",
      "episode columns: [0, 1, 4, 2, 3] epsilon: 0.9 learning rate: 0.09 error: 0.35\n",
      "episode policy:[0, 2, 1] train accuracy: 0.8264428980761359 test accuracy: 0.7808471454880295\n",
      "episode 17 end\n",
      "episode 18 start\n",
      "episode columns: [2, 4, 0, 3, 1] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 18 end\n",
      "episode 19 start\n",
      "episode columns: [1, 2, 3, 4] epsilon: 0.9 learning rate: 0.09 error: 0.09999999999999998\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 19 end\n",
      "episode 20 start\n",
      "episode columns: [3, 4, 1, 2, 0] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 20 end\n",
      "episode 21 start\n",
      "episode columns: [3, 1, 2, 0, 4] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 21 end\n",
      "episode 22 start\n",
      "episode columns: [4, 3, 1, 2, 0] epsilon: 0.9 learning rate: 0.09 error: 0.25\n",
      "episode policy:[4, 1, 2, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7661141804788214\n",
      "episode 22 end\n",
      "episode 23 start\n",
      "episode columns: [2, 0, 3, 4, 1] epsilon: 0.9 learning rate: 0.09 error: 0.4\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 23 end\n",
      "episode 24 start\n",
      "episode columns: [1, 0, 2] epsilon: 0.9 learning rate: 0.09 error: 0.09999999999999998\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 24 end\n",
      "episode 25 start\n",
      "episode columns: [1, 2, 3, 0, 4] epsilon: 0.9 learning rate: 0.09 error: 0.25\n",
      "episode policy:[2, 1] train accuracy: 0.826647564469914 test accuracy: 0.7808471454880295\n",
      "episode 25 end\n",
      "episode 26 start\n",
      "episode columns: [4, 3, 1, 0, 2] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[4, 1, 2, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7679558011049724\n",
      "episode 26 end\n",
      "episode 27 start\n",
      "episode columns: [1, 4] epsilon: 0.9 learning rate: 0.09 error: 0.09999999999999998\n",
      "episode policy:[4, 1, 2, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7642725598526704\n",
      "episode 27 end\n",
      "episode 28 start\n",
      "episode columns: [4, 2, 0, 3, 1] epsilon: 0.9 learning rate: 0.09 error: 0.15000000000000002\n",
      "episode policy:[4, 1, 2, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7716390423572744\n",
      "episode 28 end\n",
      "episode 29 start\n",
      "episode columns: [3, 0, 4, 2, 1] epsilon: 0.9 learning rate: 0.09 error: 0.15000000000000002\n",
      "episode policy:[4, 1, 2, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7716390423572744\n",
      "episode 29 end\n",
      "episode 30 start\n",
      "episode columns: [2, 4, 1, 3] epsilon: 0.9 learning rate: 0.09 error: 0.19999999999999996\n",
      "episode policy:[4, 1, 2, 0] train accuracy: 0.8223495702005731 test accuracy: 0.7605893186003683\n",
      "episode 30 end\n"
     ]
    }
   ],
   "source": [
    "for e in range (number_of_experiment):\n",
    "    if not os.path.exists('Experiments/'+ str(experiment)+ '/'+ str(e)):\n",
    "        os.makedirs('Experiments/'+ str(experiment)+ '/'+ str(e))\n",
    "    else:\n",
    "        shutil.rmtree('Experiments/'+ str(experiment)+ '/'+ str(e))          #removes all the subdirectories!\n",
    "        os.makedirs('Experiments/'+ str(experiment)+ '/'+ str(e))\n",
    "    print ('Experiments ' + str(e) + ' start')\n",
    "##########################Experiment setup##########################\n",
    "    # Read the data\n",
    "    data = pd.read_csv(location + '/' + filename, index_col=0)\n",
    "    \n",
    "##### for run time - start #####\n",
    "    import timeit\n",
    "    start = timeit.default_timer()\n",
    "    size= int(N_data* len(data.index))\n",
    "    data = data.sample(n=size)\n",
    "    data=data.iloc[:,-N_features-1:]\n",
    "##### for run time - end #####\n",
    "    \n",
    "    #Set the number of iterations:\n",
    "    interations=10*len(data.index)/episode_size\n",
    "    # Set the number of columns exclude the class column\n",
    "    number_of_columns=data.shape[1]-1 \n",
    "    print (\"number of columns: \"+ str(number_of_columns) +\" (exclude class column)\" ) \n",
    "    # Set the number of episodes \n",
    "    # episodes_number=epocs*len(data.index)/episode_size\n",
    "    episodes_number=interations\n",
    "    print (\"Number of episodes: \"+ str(episodes_number) ) \n",
    "    # Initialize matrix Q as a 1 values matrix:\n",
    "    #Q = np.matrix(np.ones([number_of_columns+1,number_of_columns+1])) # we will use the last dummy columns as initial state s\n",
    "    Q = np.matrix(np.ones([number_of_columns+1,number_of_columns+1])) # we will use the last dummy columns as initial state s\n",
    "    # Set initial_state to be the last dummy column we have created\n",
    "    initial_state=number_of_columns\n",
    "    # define data frame to save episode policies results\n",
    "    df = pd.DataFrame(columns=('episode','episode_columns','policy_columns','policy_accuracy_train','policy_accuracy_test'))\n",
    "    print (\"initial state number: \"+ str(initial_state) + \" (the last dummy column we have created)\") \n",
    "\n",
    "    ##########################  episode  ##########################  \n",
    "    for i in range (int(episodes_number)):\n",
    "    ########## Begining of episode  ############\n",
    "        # Initiate lists for available_act, episode_columns and and the policy mode & episode_error\n",
    "        episode_available_act=list(np.arange(number_of_columns))\n",
    "        episode_columns=[]\n",
    "        policy=0\n",
    "        episode_error=0\n",
    "        # Initiate the error to 0.5\n",
    "        episode_last_error=0.5\n",
    "        # Initiate current_state to be initial_state\n",
    "        episode_current_state=initial_state\n",
    "        # Create the episode data \n",
    "        episode= get_data(episode_size, policy=0, mode='train')\n",
    "        # Separate the episode data into features and label\n",
    "        X_episode,y_episode=data_separate(episode)\n",
    "        # Split the data into train and test \n",
    "        X_train_main_episode, X_test_main_episode, y_train_episode, y_test_episode = data_split(X_episode,y_episode)\n",
    "        if i<episodes_number*0.25:\n",
    "            epsilon=0.9\n",
    "            learning_rate=0.09\n",
    "        elif i<episodes_number*0.5:\n",
    "            epsilon=0.5\n",
    "            learning_rate=0.05\n",
    "        elif i<episodes_number*0.75:\n",
    "            epsilon=0.3\n",
    "            learning_rate=0.01\n",
    "        else:\n",
    "            epsilon=0.1\n",
    "            learning_rate=0.005\n",
    "        ########## Q learning start ############\n",
    "\n",
    "        while len(episode_available_act)>0:\n",
    "            # Get exploration or explotation flag \n",
    "            exploration=exploration_explotation(epsilon)\n",
    "            # Get available actions in the current state\n",
    "            episode_available_act = available_actions(number_of_columns,episode_columns,initial_state,episode_current_state,internal_trashold,exploration)\n",
    "            if len(episode_available_act)>0:\n",
    "                # Sample next action to be performed\n",
    "                episode_action = sample_next_action(episode_current_state, Q, episode_available_act, exploration)\n",
    "                # Update the episode_columns\n",
    "                episode_columns=update_columns(episode_action,episode_columns)\n",
    "                # Update the dataset to include all episode columns + current selected action (column)\n",
    "                X_train_episode, X_test_episode =update_X_train_X_test(episode_columns,X_train_main_episode, X_test_main_episode)\n",
    "                # Update the accuracy of the current columns\n",
    "                episode_error= Learner(X_train_episode, X_test_episode, y_train_episode, y_test_episode)\n",
    "                # Update reward\n",
    "                episode_reward=episode_last_error-episode_error\n",
    "                # Update Q matrix\n",
    "                q_update(episode_current_state,episode_action,learning_rate, episode_reward)\n",
    "                # Update parameters for next round \n",
    "#                 if episode_current_state==initial_state:\n",
    "#                     beta=abs(episode_reward-Q[episode_current_state,episode_action])\n",
    "#                     epsilon=final_epsilon+(beta*(1-final_epsilon))\n",
    "                #    learning_rate=final_learning_rate+(beta*(1-final_learning_rate))\n",
    "                episode_current_state=episode_action\n",
    "                episode_last_error=episode_error\n",
    "                 \n",
    "        ########## Q learning End ############\n",
    "\n",
    "        #Save Q matrix: \n",
    "        if (i%100 ==0):\n",
    "            Q_save=pd.DataFrame(Q)\n",
    "            Q_save.to_csv('Experiments/'+ str(experiment)+ '/'+ str(e)+ '/Q.'+ str(i+1) + '.csv') \n",
    "\n",
    "        # Calculate policy \n",
    "        policy_available_actions=list(np.arange(number_of_columns))\n",
    "        policy_columns=[]\n",
    "        policy_current_state=initial_state\n",
    "        while len(policy_available_actions)>0:\n",
    "            # Get available actions in the current state\n",
    "            policy_available_actions = available_actions(number_of_columns,policy_columns,initial_state,policy_current_state, external_trashold, exploration=0)\n",
    "            # # Sample next action to be performed\n",
    "            if len(policy_available_actions)>0:\n",
    "                policy_select_action = sample_next_action(policy_current_state, Q, policy_available_actions, exploration=0)\n",
    "                # Update the episode_columns\n",
    "                policy_columns=update_columns(policy_select_action,policy_columns)\n",
    "                policy_current_state=policy_select_action\n",
    "        # Calculate policy_accuracy    \n",
    "        if len(policy_columns)>0:\n",
    "            ##for training dataset##\n",
    "            policy_data=get_data(episode_size,policy=1,mode='train')\n",
    "            X_policy,y_policy=data_separate(policy_data)\n",
    "            X_train_main_policy, X_test_main_policy, y_train_policy, y_test_policy = data_split(X,y)\n",
    "            X_train_policy, X_test_policy =update_X_train_X_test(policy_columns, X_train_main_policy, X_test_main_policy)\n",
    "            policy_error=Learner(X_train_policy, X_test_policy,y_train_policy, y_test_policy)\n",
    "            policy_accuracy_train=1-policy_error\n",
    "            ##for testing dataset##\n",
    "            policy_data=get_data(episode_size,policy=1,mode='test')\n",
    "            X_policy,y_policy=data_separate(policy_data)\n",
    "            X_train_main_policy, X_test_main_policy, y_train_policy, y_test_policy = data_split(X,y)\n",
    "            X_train_policy, X_test_policy =update_X_train_X_test(policy_columns, X_train_main_policy, X_test_main_policy)\n",
    "            policy_error=Learner(X_train_policy, X_test_policy,y_train_policy, y_test_policy)\n",
    "            policy_accuracy_test=1-policy_error \n",
    "        else:\n",
    "            policy_accuracy_train=0 \n",
    "            policy_accuracy_test=0\n",
    "        df=df.append({'episode':str(i+1), 'episode_columns':str(episode_columns),'policy_columns':str(policy_columns),'policy_accuracy_train':policy_accuracy_train,'policy_accuracy_test':policy_accuracy_test}, ignore_index=True)\n",
    "        #Prints\n",
    "        print (\"episode \"+ str(i+1) +\" start\") \n",
    "        print (\"episode columns: \"+ str(episode_columns) + \" epsilon: \" + str(epsilon) + \" learning rate: \" + str(learning_rate) + \" error: \" +str(episode_error))\n",
    "        print (\"episode policy:\" + str(policy_columns) + \" train accuracy: \" + str(policy_accuracy_train)  + \" test accuracy: \" +str(policy_accuracy_test)) \n",
    "        print (\"episode \"+ str(i+1) +\" end\") \n",
    "    ########## End of episode  ############\n",
    "    df.to_excel(writer, 'Experiment' + str(e))\n",
    "    df_plot=df[['episode','policy_accuracy_train','policy_accuracy_test']]\n",
    "    plot=df_plot.plot()\n",
    "    fig = plot.get_figure()\n",
    "    fig.savefig('Experiments/'+ str(experiment) + '/plot_experiment_' + str(e) +'.png')\n",
    "writer.save()\n",
    "## for run time ##\n",
    "stop = timeit.default_timer()\n",
    "print (stop - start)\n",
    "## for run time ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
