{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de98c52-7704-4f7c-974c-235bcd43a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def make_staircase_dataset(n_samples=1000, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    # Create three uncorrelated signals uniformly in [-1, 1]\n",
    "    s0 = rng.uniform(low=-1.0, high=1.0, size=n_samples)\n",
    "    s1 = rng.uniform(low=-1.0, high=1.0, size=n_samples)\n",
    "    s2 = rng.uniform(low=-1.0, high=1.0, size=n_samples)\n",
    "\n",
    "    # Generate label from a thresholded linear combination\n",
    "    raw_score = 1.0 * s0 + 0.8 * s1 + 0.5 * s2\n",
    "    y = (raw_score > 0).astype(int)\n",
    "\n",
    "    # Add small noise\n",
    "    noise_scale = 0.05\n",
    "    f0 = s0 #+ rng.normal(0, noise_scale, n_samples)\n",
    "    f1 = s1 #+ rng.normal(0, noise_scale, n_samples)\n",
    "    f2 = s2 #+ rng.normal(0, noise_scale, n_samples)\n",
    "\n",
    "    # 3 pure noise features\n",
    "    f3_5 = rng.uniform(low=-1.0, high=1.0, size=(n_samples, 3))\n",
    "\n",
    "    X = np.column_stack([f0, f1, f2, f3_5])\n",
    "    df = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(6)])\n",
    "    df[\"target\"] = y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edf075d6-03e0-4f4f-aa31-935343dc08e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetMajorityVQC:\n",
    "    def __init__(self, coeffs):\n",
    "        \"\"\"\n",
    "        coeffs: list of feature coefficients, e.g., [1.0, 0.8, 0.5, 0.0, 0.0, 0.0]\n",
    "        Nonzero coeffs indicate which features are included in the majority subset.\n",
    "        \"\"\"\n",
    "        self.coeffs = np.array(coeffs, dtype=float)\n",
    "        self.num_qubits = len(self.coeffs)\n",
    "        wires = list(range(self.num_qubits + 1))  # +1 for readout qubit\n",
    "        self.dev = qml.device(\"default.qubit\", wires=wires)\n",
    "\n",
    "        self.beta = 0.9 * np.pi / self.num_qubits  # as suggested in the theory\n",
    "\n",
    "        self._initialize_circuit()\n",
    "\n",
    "    def state_preparation(self, x):\n",
    "        \"\"\"Prepare the input via RX rotations.\"\"\"\n",
    "        for j in range(self.num_qubits):\n",
    "            qml.RX(np.pi * x[j], wires=j)\n",
    "        qml.PauliX(wires=self.num_qubits)  # Set readout qubit to |1>\n",
    "\n",
    "    def apply_subset_majority_unitary(self):\n",
    "        \"\"\"Implements U_MS = exp(i (Î²/2) sum_j a_j Z_j X_readout).\"\"\"\n",
    "        for j in range(self.num_qubits):\n",
    "            if self.coeffs[j] != 0:\n",
    "                qml.CNOT(wires=[j, self.num_qubits])\n",
    "                qml.RX(self.beta, wires=self.num_qubits)\n",
    "                qml.CNOT(wires=[j, self.num_qubits])\n",
    "\n",
    "    def _initialize_circuit(self):\n",
    "        @qml.qnode(self.dev, interface=\"autograd\")\n",
    "        def circuit(x):\n",
    "            self.state_preparation(x)\n",
    "            self.apply_subset_majority_unitary()\n",
    "            return qml.expval(qml.PauliY(wires=self.num_qubits))\n",
    "\n",
    "        self.circuit = circuit\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predicts class labels (0 or 1).\"\"\"\n",
    "        X = np.array(X, dtype=np.float64)\n",
    "        preds = np.array([\n",
    "            1 if self.circuit(x) > 0 else 0\n",
    "            for x in X\n",
    "        ])\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429615c1-d51b-4f6e-9703-6afec8483699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_hardcoded(model, df, features, label):\n",
    "    \"\"\"Evaluate a non-trainable VQC model (like SubsetMajorityVQC).\"\"\"\n",
    "    X = df[[f\"f{i}\" for i in features]].values\n",
    "    y = df[\"target\"].values\n",
    "\n",
    "    # No scaling needed; assuming features are already in [-1,1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # No training step!\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"{label:<20} | Train: {acc_train:.4f} | Test: {acc_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a62335a-ea20-4670-a898-1ddc22af53e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Running sanity checks on staircase_dataset...\n",
      "\n",
      "=== Angleâ€Encoded VQC ===\n",
      "f0                   | Train: 0.5000 | Test: 0.5450\n",
      "f0 + f1              | Train: 0.5000 | Test: 0.5450\n",
      "f0 + f2              | Train: 0.5000 | Test: 0.5450\n",
      "f0 + f3 (noise)      | Train: 0.5000 | Test: 0.5450\n",
      "f0 + f4 (noise)      | Train: 0.5000 | Test: 0.5450\n",
      "f0 + f5 (noise)      | Train: 0.5000 | Test: 0.5450\n",
      "f0 + f1 + f2         | Train: 0.5000 | Test: 0.5450\n"
     ]
    }
   ],
   "source": [
    "def run_sanity_check():\n",
    "    print(\"\\nðŸ” Running sanity checks on staircase_dataset...\\n\")\n",
    "    df = make_staircase_dataset()\n",
    "\n",
    "    # extend signal coeffs [1.0, 0.8, 0.5] to match 6 features by zeroing noise\n",
    "    base_coeffs = [1.0, 0.8, 0.5] + [0.0] * 3  # now length == 6\n",
    "\n",
    "    feature_sets = [\n",
    "        ([0],       \"f0\"),\n",
    "        ([0, 1],    \"f0 + f1\"),\n",
    "        ([0, 2],    \"f0 + f2\"),\n",
    "        ([0, 3],    \"f0 + f3 (noise)\"),\n",
    "        ([0, 4],    \"f0 + f4 (noise)\"),\n",
    "        ([0, 5],    \"f0 + f5 (noise)\"),\n",
    "        ([0, 1, 2], \"f0 + f1 + f2\"),\n",
    "    ]\n",
    "\n",
    "    print(\"=== Angleâ€Encoded VQC ===\")\n",
    "    for features, label in feature_sets:\n",
    "        coeffs = [base_coeffs[i] for i in features]\n",
    "        model = SubsetMajorityVQC(coeffs)\n",
    "        evaluate_model_hardcoded(model, df, features, label)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7b466-7a8f-4656-8881-081276794ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
